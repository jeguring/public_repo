{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# 기본값 : torch.nn.Conv2d(in_channesls, out_channels, kernel_size, stride=1, padding=0, bias=True)\n",
    "conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=11, stride=4,padding=0)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.Tensor(1,1,227,227)\n",
    "outputs = conv(inputs)\n",
    "print(outputs)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=7,stride=2, padding=0)\n",
    "print(conv)\n",
    "inputs = torch.Tensor(1,1,64,64)\n",
    "outputs = conv(inputs)\n",
    "print(outputs)\n",
    "print('outputs shape:',outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=5,stride=1, padding=2)\n",
    "print(conv)\n",
    "inputs = torch.Tensor(1,1,32,632)\n",
    "outputs = conv(inputs)\n",
    "print(outputs)\n",
    "print('outputs shape:',outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 4\n",
    "conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=5,stride=1, padding=0)\n",
    "print(conv)\n",
    "inputs = torch.Tensor(1,1,32,64)\n",
    "outputs = conv(inputs)\n",
    "print(outputs)\n",
    "print('outputs shape:',outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 5\n",
    "conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3,stride=1, padding=1)\n",
    "print(conv)\n",
    "inputs = torch.Tensor(1,1,64,32)\n",
    "outputs = conv(inputs)\n",
    "print(outputs)\n",
    "print('outputs shape:',outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.MaxPool2d(kernel_size)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "inputs = torch.Tensor(1,1,28,28)\n",
    "conv1 = nn.Conv2d(in_channels=1, out_channels=5,kernel_size=5)\n",
    "pool = nn.MaxPool2d(2)\n",
    "out = conv1(inputs)\n",
    "out2 = pool(out)\n",
    "print(out.size())\n",
    "print(out2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-10-2 mnist cnn\n",
    "1. 라이브러리를 가져온다 (torch, torchvision, matplotlib)\n",
    "2. GPU 사용 설정하고 random value를 위한 seed 설정\n",
    "3. 학습에 사용되는 parameter 설정 (learning_rate, training_epochs, batch_size, etc)\n",
    "4. 데이터셋을 가져오고 (학습에 쓰기 편하기) loader 만들기\n",
    "5. 학습 모델 만들기 (`class CNN(torch.nn.Module)`)\n",
    "6. Loss function (Criterion)을 선택하고 최적화 도구 선택(Optimizer)\n",
    "7. 모델 학습 및 Loss check(Criterion의 Output)\n",
    "8. 학습된 모델의 성능을 확인한다.\n",
    "\n",
    "## 우리가 만들 CNN 구조\n",
    "- 데이터 -> Layer1(Conv->ReLU->MaxPool) -> Layer2(Conv->ReLU->MaxPool) -> view -> FC -> Cross Entropy Loss(SoftMax -> NLL loss)\n",
    "- (Layer1) Convolution layer = (in_c=1, out_c=32, kernel_size=3, stride=1, padding=1)\n",
    "- (Layer1) MaxPool layer = (kernel_size=2, stride=2)\n",
    "\n",
    "- (Layer2) Convolution layer = (in_c=32, out_c=64, kernel_size=3, stride=1, padding=1)\n",
    "- (Layer2) MaxPool layer = (kernel_size=2, stride=2)\n",
    "\n",
    "- view => (batch_size x [7,7,64] => batch_size x [3136])\n",
    "- Fully_Conneted layer => (input=3136, output=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "class CNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # L1 ImgIn shape = (?, 28, 28, 1)\n",
    "        # conv -> (?, 28, 28, 32)\n",
    "        # Pool -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # L2 ImgIn shape = (?, 14, 14, 32)\n",
    "        # Conv -> (?, 14, 14, 64)\n",
    "        # Pool -> (?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # Final FC 7*7*64 inputs -> 10 outputs\n",
    "        self.fc = torch.nn.Linear(in_features=7*7*64, out_features=10, bias=True)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1) \n",
    "        # Flatten them for FC\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate CNN model\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "# Softmax is internally computed\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train my model\n",
    "total_batch = len(data_loader)\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab-10-4-1 ImageFolder1\n",
    "https://www.youtube.com/watch?v=KDVOAjaTnDU&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv&index=22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline # Notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.Resize((64,128))\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=\"/home/hb/python/public-repo/deeplearningzerotoall/PyTorch/custom_data/origin_data\", transform=trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`transforms` 함수는 이미지 형태를 변경해주는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, value in enumerate(train_data):\n",
    "    data, label = value\n",
    "    print(num, data, label)\n",
    "\n",
    "    if(label == 0):\n",
    "        data.save('/home/hb/python/public-repo/deeplearningzerotoall/PyTorch/custom_data/origin_data/gray/%d_%d.jpeg'%(num, label))\n",
    "    else:\n",
    "        data.save('/home/hb/python/public-repo/deeplearningzerotoall/PyTorch/custom_data/origin_data/red/%d_%d.jpeg'%(num,label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab-10-4-2 ImageFolder2\n",
    "https://www.youtube.com/watch?v=NqwUmCZbjNA&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv&index=23\n",
    "\n",
    "- Lab-10-4-2에서는 `ImageFolder` 사용법 공부\n",
    "- 오늘은 내 사진을 분류하는 딥러닝 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. GPU 사용 설정 및 random value를 위한 seed 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device =='cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 데이터셋을 가져오고 (학습에 쓰기 편하게) loader만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root='/home/hb/python/public-repo/deeplearningzerotoall/PyTorch/custom_data/train_data', transform=trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset = train_data, batch_size = 8, shuffle = True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 학습 모델 만들기 (`class CNN(torch.nn.Module)`)\n",
    "\n",
    "<img src=\"/home/hb/python/public-repo/image/스크린샷 2022-06-07 오후 9.57.03.png\" width='600' height='400'/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3,6,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6,16,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(16*13*29, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120,2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.layer3(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.* testing\n",
    "중간에 `print(out.shape)`를 넣고 아래 코드를 돌리면 layer3에 넣어줘야 될 fc의 형태를 알 수 있다.\n",
    "\n",
    "torch.Size([3, 6, 30, 62])  \n",
    "torch.Size([3, 16, 13, 29])  \n",
    "torch.Size([3, 6032])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing \n",
    "net = CNN().to(device)\n",
    "test_input = (torch.Tensor(3,3,64,128)).to(device)\n",
    "test_out = net(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Loss function (Criterion)을 선택하고, 최적화 도구 선택(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.00005)\n",
    "loss_func = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 모델 학습 및 Loss check (Criterion의 output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:1] cost = 0.6551641225814819\n",
      "[Epoch:2] cost = 0.49421167373657227\n",
      "[Epoch:3] cost = 0.23495927453041077\n",
      "[Epoch:4] cost = 0.06872614473104477\n",
      "[Epoch:5] cost = 0.026471389457583427\n",
      "[Epoch:6] cost = 0.013910708017647266\n",
      "[Epoch:7] cost = 0.008653281256556511\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "\n",
    "epochs = 7\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0.0\n",
    "    for num, data in enumerate(data_loader):\n",
    "        imgs, labels = data\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = net(imgs)\n",
    "        loss = loss_func(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += loss / total_batch\n",
    "        \n",
    "    print('[Epoch:{}] cost = {}'.format(epoch+1, avg_cost))\n",
    "print('Learning Finished!')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-1. 학습한 모델 저장 후 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.mkdir(\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"./model/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_net.load_state_dict(torch.load('./model/model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "tensor([-0.0915,  0.0031, -0.0173, -0.0214,  0.0929], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([-0.0915,  0.0031, -0.0173, -0.0214,  0.0929], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True]]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(net.layer1[0])\n",
    "print(new_net.layer1[0])\n",
    "\n",
    "print(net.layer1[0].weight[0][0][0])\n",
    "print(new_net.layer1[0].weight[0][0][0])\n",
    "\n",
    "net.layer1[0].weight[0] == new_net.layer1[0].weight[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 학습시킨 데이터를 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = torchvision.transforms.Compose([\n",
    "    transforms.Resize((64,128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(root='/home/hb/python/public-repo/deeplearningzerotoall/PyTorch/custom_data/test_data', transform=trans\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = DataLoader(dataset = test_data, batch_size = len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for num, data in enumerate(test_set):\n",
    "        imgs, label = data\n",
    "        imgs = imgs.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        prediction = net(imgs)\n",
    "        \n",
    "        correct_prediction = torch.argmax(prediction, 1) == label\n",
    "        \n",
    "        accuracy = correct_prediction.float().mean()\n",
    "        print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78f8049be311e578f52a502ceb941e702d1aebc0ae697b457cf7941b91578c1d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('pp_predict')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
